{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c07e1bb5-6376-49fc-8a25-fe4859399798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f9b0e3-a8a6-4ae3-b027-061867773c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the dataset\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Step 3: Convert to pandas DataFrame\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target  # Add target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57acbd5d-3fb5-4eec-9911-7d9cd60985da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Check for missing values\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da30a1-8dca-4464-b7ae-a12f8b7de233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is no missing value in breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf7e13fc-cc2d-4931-a79c-85b34c021d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
       "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
       "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          3.283515        2.652874             2.532475       2.217515   \n",
       "1         -0.487072       -0.023846             0.548144       0.001392   \n",
       "2          1.052926        1.363478             2.037231       0.939685   \n",
       "3          3.402909        1.915897             1.451707       2.867383   \n",
       "4          0.539340        1.371011             1.428493      -0.009560   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                2.255747  ...      -1.359293         2.303601    2.001237   \n",
       "1               -0.868652  ...      -0.369203         1.535126    1.890489   \n",
       "2               -0.398008  ...      -0.023974         1.347475    1.456285   \n",
       "3                4.910919  ...       0.133984        -0.249939   -0.550021   \n",
       "4               -0.562450  ...      -1.466770         1.338539    1.220724   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          1.307686           2.616665         2.109526              2.296076   \n",
       "1         -0.375612          -0.430444        -0.146749              1.087084   \n",
       "2          0.527407           1.082932         0.854974              1.955000   \n",
       "3          3.394275           3.893397         1.989588              2.175786   \n",
       "4          0.220556          -0.313395         0.613179              0.729259   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        2.750622                 1.937015       0  \n",
       "1       -0.243890                 0.281190       0  \n",
       "2        1.152255                 0.201391       0  \n",
       "3        6.046041                 4.935010       0  \n",
       "4       -0.868353                -0.397100       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Feature Scaling (Standardization)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df.drop('target', axis=1))\n",
    "\n",
    "\n",
    "# Step 7: Create a new DataFrame for the scaled features\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=data.feature_names)\n",
    "X_scaled_df['target'] = df['target'].values  # Add the target column back\n",
    "\n",
    "# Preview the scaled data\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc3669-f363-40e1-aa97-c4de09775d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation of each step\n",
    "\n",
    "#CHECKING FOR MISSING VALUE\n",
    "#We use df.isnull().sum() to identify any columns with missing data.\n",
    "\n",
    "#In this dataset, there are no missing values\n",
    "\n",
    "\n",
    "\n",
    "# fEATURE SCALING (Standardization)\n",
    "# We use StandardScaler() to ensure all features have mean = 0 and standard deviation = 1.\n",
    "\n",
    "#This is important because:\n",
    "\n",
    "#Many machine learning models (e.g., SVM, KNN, Logistic Regression) are sensitive to the scale of features.\n",
    "\n",
    "#The Breast Cancer dataset has features like mean area and mean smoothness on very different scales.\n",
    "\n",
    "#Scaling helps the model converge faster and improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c568b956-240d-4acf-a821-fddc7311e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qn 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f624c2bf-e04f-4b38-b08a-7482cf59ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bd3bc2a-2f99-4b2a-8800-25ef88b248a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "\n",
    "X = X_scaled_df.drop('target', axis=1)\n",
    "y = X_scaled_df['target']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9edb7df-caf5-42c0-bc16-fe1e42c69cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Train Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10e744fd-2e9d-442b-be0f-672b319d7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Logistic Regression\n",
      "Accuracy: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "* Decision Tree\n",
      "Accuracy: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.93      0.93        43\n",
      "      benign       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "\n",
      "* Random Forest\n",
      "Accuracy: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.93      0.95        43\n",
      "      benign       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "\n",
      "* Support Vector Machine\n",
      "Accuracy: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "* k-Nearest Neighbors\n",
      "Accuracy: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.93      0.93        43\n",
      "      benign       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define all models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n* {name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e2c34d-72f6-4865-b1d1-3ff921017dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALGORITHM EXPLATION\n",
    "\n",
    "# 1 Logistic Regression\n",
    "#How it works: Uses the logistic (sigmoid) function to model the probability that an input belongs to a certain class. It's a linear model used for binary classification.\n",
    "\n",
    "#Why suitable: This dataset is binary (malignant vs. benign), and logistic regression is often a strong baseline for classification tasks.\n",
    "\n",
    "\n",
    "# 2 Decision Tree Classifier\n",
    "# How it works: Splits the dataset into branches using rules based on feature values. Each branch ends in a decision (leaf node).\n",
    "\n",
    "# Why suitable: Captures non-linear relationships, handles both numerical and categorical data, and is interpretable.\n",
    "\n",
    "\n",
    "# 3 Random Forest Classifier\n",
    "# How it works: An ensemble of decision trees trained on random subsets of data and features. Final prediction is a majority vote.\n",
    "\n",
    "# Why suitable: Reduces overfitting, improves accuracy, and handles feature interactions well. Very effective for structured/tabular data like this.\n",
    "\n",
    "\n",
    "# 4 Random Forest Classifier\n",
    "# How it works: An ensemble of decision trees trained on random subsets of data and features. Final prediction is a majority vote.\n",
    "\n",
    "# Why suitable: Reduces overfitting, improves accuracy, and handles feature interactions well. Very effective for structured/tabular data like this.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5  k-Nearest Neighbors (k-NN)\n",
    "# How it works: Classifies a data point based on the majority class of its k nearest neighbors.\n",
    "\n",
    "# Why suitable: Simple and effective for small datasets. Performance depends on the distance metric, which works better when features are scaled (we used StandardScaler).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1838fb2e-b7f4-4ff5-9e78-88004f78d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qn 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81d2738d-d1a6-4280-98a1-53eb9427a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Logistic Regression\n",
      "Accuracy: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "* Decision Tree\n",
      "Accuracy: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.93      0.93        43\n",
      "      benign       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "\n",
      "* Random Forest\n",
      "Accuracy: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.93      0.95        43\n",
      "      benign       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "\n",
      "* Support Vector Machine\n",
      "Accuracy: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "\n",
      "* k-Nearest Neighbors\n",
      "Accuracy: 0.9474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.93      0.93        43\n",
      "      benign       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Dictionary to store accuracy results\n",
    "accuracy_results = {}\n",
    "\n",
    "# Evaluate all models\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracy_results[name] = acc\n",
    "    print(f\"\\n* {name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d727314-9f6a-4097-8fdb-5c220498ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Performing Model: Random Forest Classifier\n",
    "# Accuracy: ~97%\n",
    "\n",
    "# Why it performed best:\n",
    "\n",
    "# Combines multiple decision trees, reducing overfitting.\n",
    "\n",
    "# Handles complex interactions between features.\n",
    "\n",
    "# Performs robustly even with minor data noise.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Worst Performing Model: Decision Tree Classifier\n",
    "#Accuracy: ~91%\n",
    "\n",
    "Why it performed worst:\n",
    "\n",
    "Single decision trees can overfit easily, especially without pruning or regularization.\n",
    "\n",
    "Less stable compared to ensemble methods (like Random Forest).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
